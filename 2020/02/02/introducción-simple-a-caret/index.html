<!DOCTYPE html>
<html lang="es-ar"><head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	<meta name="generator" content="Hugo 0.58.3" />
	
	<link rel="icon" href="/images/logo.png">
	
	<title>Introducción (simple) a caret | el radaR</title>
	
	

	<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Introducción (simple) a caret"/>
<meta name="twitter:description" content="Agradecemos a German Rosati, experto en Machine Learning en el contexto de las Ciencias Sociales, por este tutorial que explica como podemos realizar Aprendizaje Automático en forma organizada y sucinta utilizando caret, el tradicional paquete de R para producir modelos predictivos."/>

	<meta property="og:title" content="Introducción (simple) a caret" />
<meta property="og:description" content="Agradecemos a German Rosati, experto en Machine Learning en el contexto de las Ciencias Sociales, por este tutorial que explica como podemos realizar Aprendizaje Automático en forma organizada y sucinta utilizando caret, el tradicional paquete de R para producir modelos predictivos." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://elradar.github.io/2020/02/02/introducci%C3%B3n-simple-a-caret/" />
<meta property="article:published_time" content="2020-02-02T12:23:05-03:00" />
<meta property="article:modified_time" content="2020-02-02T00:00:00+00:00" />


	<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp"
	 crossorigin="anonymous">
	<link href="https://fonts.googleapis.com/css?family=Righteous%7CMerriweather:300,300i,400,400i,700,700i" rel="stylesheet">
	<link href="/css/medium.css" rel="stylesheet">
	<link href="/css/additional.css" rel="stylesheet">
</head>
<body>
<nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top mediumnavigation nav-down">
    <div class="container pr-0">
        
        <a class="navbar-brand" href="https://elradar.github.io/">

            
            <img src="/images/logo.png" alt="logo">
            
        </a>
        

        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarMediumish" aria-controls="navbarSupportedContent"
            aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        
        <div class="collapse navbar-collapse" id="navbarMediumish">
            
            <ul class="navbar-nav ml-auto">
                 
                <li class="nav-item ">
                    <a class="nav-link" href="/post">Posts</a>
                </li>
                
            </ul>
        </div>
        
    </div>
</nav>


        <div class="site-content">   
            <div class="container">
<div class="mainheading">
    <h1 class="sitetitle">el radaR</h1>
    <p class="lead">
         detectando los paquetes y proyectos en R que tenés que conocer
    </p>
</div><div class="main-content">
        
        <div class="container">
            <div class="row">
                
                <div class="col-md-2 pl-0"><div class="share sticky-top sticky-top-offset">
    <p>Compartir</p>
    <ul>
        <li class="ml-1 mr-1">
        <a target="_blank" href="https://twitter.com/intent/tweet?text=Introducci%c3%b3n%20%28simple%29%20a%20caret&url=https%3a%2f%2felradar.github.io%2f2020%2f02%2f02%2fintroducci%25C3%25B3n-simple-a-caret%2f" onclick="window.open(this.href, 'twitter-share', 'width=550,height=435');return false;">
        <i class="fab fa-twitter"></i>
        </a>
        </li>
        
        <li class="ml-1 mr-1">
        <a target="_blank" href="https://facebook.com/sharer.php?u=https%3a%2f%2felradar.github.io%2f2020%2f02%2f02%2fintroducci%25C3%25B3n-simple-a-caret%2f" onclick="window.open(this.href, 'facebook-share', 'width=550,height=435');return false;">
        <i class="fab fa-facebook-f"></i>
        </a>
        </li>

        <li class="ml-1 mr-1">
        <a target="_blank" href="https://www.xing.com/spi/shares/new?url=https%3a%2f%2felradar.github.io%2f2020%2f02%2f02%2fintroducci%25C3%25B3n-simple-a-caret%2f" onclick="window.open(this.href, 'xing-share', 'width=550,height=435');return false;">
        <i class="fab fa-xing"></i>
        </a>
        </li>        
    </ul>

    
        <div class="sep">
        </div>				
        <ul>
            <li> 
            <a  class="small smoothscroll" href="#disqus_thread"></a>
            </li>
        </ul>
    
</div>
</div>
                                
                <div class="col-md-9 flex-first flex-md-unordered">
                    <div class="mainheading">
                        	
                                                
                        
                        <h1 class="posttitle">Introducción (simple) a caret</h1> 
                    </div>

                    
                    
                    
                    

                    
                    <div class="article-post">
                        


<p><em>Agradecemos a <a href="https://gefero.github.io/">German Rosati</a>, experto en Machine Learning en el contexto de las Ciencias Sociales, por este tutorial que explica como podemos realizar Aprendizaje Automático en forma organizada y sucinta utilizando <code>caret</code>, el tradicional paquete de R para producir modelos predictivos.</em></p>
<div id="objetivos" class="section level2">
<h2>Objetivos</h2>
<ul>
<li>Introducir algunos conceptos básicos del enfoque del Aprendizaje Automático</li>
<li>Mostrar el framework <code>caret</code> para automatizar algunas tareas del entrenamiento</li>
</ul>
</div>
<div id="el-problema" class="section level2">
<h2>El problema</h2>
<p>Nuestro problema central es, poder realizar un modelo que logre prededir los ingresos de la ocupación principal (<code>p21</code>) en la <a href="https://www.indec.gob.ar/indec/web/Institucional-Indec-BasesDeDatos">Encuesta Permanente de Hogares</a> del segundo trimestre del 2015.</p>
<p>Puede notarse que se trata de un problema bastante amigable, por así decirlo, al enfoque de Machine Learning:</p>
<ul>
<li>tenemos un conjunto de casos en los que desconocemos nuestra variable <span class="math inline">\(Y\)</span></li>
<li>queremos predecirla</li>
<li>queremos evaluar qué tan bien funciona el modelo que usemos</li>
</ul>
</div>
<div id="pipeline-de-trabajo-para-entrenar-modelos-de-machine-learning-con-caret" class="section level2">
<h2>Pipeline de trabajo para entrenar modelos de Machine Learning con <code>caret</code></h2>
<p><img src="https://elradar.github.io/images/intro_caret/flow.png" /></p>
<div id="preprocesar-los-datos" class="section level3">
<h3>0. Preprocesar los datos</h3>
<p>Lo primero que tenemos que hacer es importar las librerías con las que vamos a trabajar: <code>tidyverse</code> y <code>caret</code>.</p>
<p>Si aún no las tenemos disponibles, las podemos instalar con:</p>
<pre class="r"><code>install.packages(&quot;tidyverse&quot;)
install.packages(&quot;caret&quot;)</code></pre>
<pre class="r"><code>library(caret)
library(tidyverse)</code></pre>
<p>Luego, cargamos los datos y formateamos un poco algunas etiquetas:</p>
<pre class="r"><code>data &lt;- read.csv(&#39;https://elradar.github.io/data/intro_caret/EPH_2015_II.csv&#39;)

data$pp03i&lt;-factor(data$pp03i, labels=c(&#39;1-SI&#39;, &#39;2-No&#39;, &#39;9-NS&#39;))



data$intensi&lt;-factor(data$intensi, labels=c(&#39;1-Sub_dem&#39;, &#39;2-SO_no_dem&#39;, 
                                            &#39;3-Ocup.pleno&#39;, &#39;4-Sobreoc&#39;,
                                            &#39;5-No trabajo&#39;, &#39;9-NS&#39;))

data$pp07a&lt;-factor(data$pp07a, labels=c(&#39;0-NC&#39;,
                                        &#39;1-Menos de un mes&#39;,
                                        &#39;2-1 a 3 meses&#39;,
                                        &#39;3-3 a 6 meses&#39;,
                                        &#39;4-6 a 12 meses&#39;,
                                        &#39;5-12 a 60 meses&#39;,
                                        &#39;6-Más de 60 meses&#39;,
                                        &#39;9-NS&#39;))</code></pre>
<p>Vale aclarar que <code>caret</code> tiene unas cuantas funciones para realizar el preprocesamiento. Pueden consultar su uso <a href="http://topepo.github.io/caret/pre-processing.html">acá</a>.</p>
<p>Existen en nuestro dataset, datos que no contestaron ingresos. Son datos perdidos y tenemos que resolver qué hacer con ellos. En este ejemplo vamos a eliminarlos. Esta opción está lejos de ser la óptima, pero la seleccionamos para simplificar el problema y la exposición.</p>
<p>En caso de que les interese el tema de imputación de missing data, les dejo dos artículos con aplicaciones de Machine Learning al problema (y sobre el mismo dataset).</p>
<ul>
<li><a href="https://www.saberes.fcecon.unr.edu.ar/index.php/revista/article/view/132">Revista Saberes</a></li>
<li><a href="https://aset.org.ar/2019/ponencias/20_Rosati.pdf">Congreso ASET 2019</a> pueden encontrar</li>
</ul>
<p>Tenemos codificados como <code>imp_inglab1==1</code> a los que no contestaron ingresos en la ocupación principal, los filtramos, entonces…</p>
<pre class="r"><code>df &lt;- data %&gt;%
        filter(imp_inglab1==0) %&gt;%
        select(-imp_inglab1) %&gt;%
        mutate(p21 = ifelse(p21==0, 100, p21))</code></pre>
<div id="algunas-cosas-a-notar" class="section level4">
<h4>Algunas cosas a notar</h4>
<p>Por un lado, vemos que encadenamos unas cuántas operaciones mediante un operador (<code>%&gt;%</code>) llamado <code>pipe</code>. El pipe es un símbolo que relaciona dos entidades. Dicho en forma más simple, el pipe de R está en familia con otros operadores más convencionales, como +, - o /. Y al igual que los otros operadores, entrega un resultado en base a los operandos que recibe.</p>
<p>Ahora bien… ¿Para qué sirve? En resumidas cuentas, hace que el código necesario para realizar una serie de operaciones de transformación de datos sea mucho más simple de escribir y de interpretar.</p>
<p>Repasemos la primer secuencia</p>
<ul>
<li>filtramos los datos con algún perdido (<code>%&gt;% filter(imp_inglab==1)</code>)</li>
<li>eliminamos la columna identificadora de los casos perdidos (<code>select(-imp_inglab)</code>)</li>
</ul>
</div>
</div>
<div id="split-o-estimando-el-error-de-generalización" class="section level3">
<h3>1. Split o Estimando el error de generalización</h3>
<p>Nos interesa testear nuestro(s) modelo(s), es decir, poder evaluar qué tan bien funcionan. Pero la trampa aquí es que queremos testearlo en datos que no hayan sido usados para entrenar el modelo. Queremos estimar lo que se llama <em>error de generalización</em>. Esto nos introduce a un problema que excede este tutorial pero que se vincula al <a href="http://scott.fortmann-roe.com/docs/BiasVariance.html"><em>bias-variace tradeoff</em></a>.</p>
<p>Para simplificar digamos si evaluamos nuestro modelo sobre los mismos datos sobre los que lo entrenamos existen “incentivos” para generar un modelo innecesariamente complejo. Pero, al mismo tiempo, no queremos que nuestro modelo sea demasiado simple. En líneas generales, los modelos demasiado complejos sufren de <em>overfitting</em> y los demasiado simples sufren de <em>underfitting</em>.</p>
<p>Tenemos muchas formas de estimar el error de generalización (train-test split, cross validation, bootstrap). Usaremos dos estrategias de validación diferentes. Primero, vamos a dividir en dos pedazos el dataset:</p>
<ul>
<li>sobre nuestro <em>train set</em> entrenaremos el modelo</li>
<li>sobre el <em>test set</em> lo validaremos.</li>
</ul>
<p>Vamos a generar los índices mediante <code>caret</code>.</p>
<p>Primero, fijamos la semilla aleatoria (para asegurarnos la posibilidad de replicabilidad)</p>
<pre class="r"><code>set.seed(957)</code></pre>
<p>Y luego generamos los índices para el split:</p>
<pre class="r"><code>train_index &lt;- createDataPartition(y = df$p21,
                                   p=0.7,
                                   list=FALSE)</code></pre>
<p>Aquí usamos tres argumentos:</p>
<ul>
<li><code>y = df_train$p21</code>, es el vector de resultados. En nuestro caso, los ingresos de la ocupación principal</li>
<li><code>p=0.7</code>, es la proporción del dataset original que formará parte del training set.</li>
<li><code>list=FALSE</code>, le decimos que lo que nos devuelva sea un vector y no una lista.</li>
</ul>
<p>Luego, generamos el split:</p>
<pre class="r"><code>df_train &lt;- df[train_index,]
df_test &lt;- df[-train_index,]</code></pre>
<p>Ahora bien, como sabemos, parte del proceso de entrenamiento es el proceso de <a href="https://en.wikipedia.org/wiki/Hyperparameter_optimization">optimización de los hiperparámetros</a>. Es por ello que tenemos que diseñar una segunda estrategia de validación: en este caso, será de <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)"><em>cross-validation</em></a>.</p>
<p>Podemos usar la función <code>createFolds()</code> para generar los índices.</p>
<pre class="r"><code>cv_index &lt;- createFolds(y = df_train$p21,
                        k=5,
                        list=TRUE,
                        returnTrain=TRUE)</code></pre>
<p>Aquí usamos tres argumentos:</p>
<ul>
<li><code>y = df_train$p21</code>, igual que en caso anterior</li>
<li><code>k=5</code>, es la cantidad de grupos para realizar la validación cruzada</li>
<li><code>returnTrain=TRUE</code>, le decimos que lo que nos devuelva, sean las posiciones de correspondientes a los datos de entrenamiento en cada posición</li>
</ul>
<div id="poniendo-todo-el-diseño-junto-train_control." class="section level4">
<h4>1.1 Poniendo todo el diseño junto: train_control.</h4>
<p>Finalmente, especificamos el diseño de remuestreo mediante la función <code>trainControl</code>:</p>
<pre class="r"><code>fitControl &lt;- trainControl(
        index=cv_index,
        method=&quot;cv&quot;,
        number=5)</code></pre>
<p><code>fitControl</code>, entonces, será el objeto que contenga nuestro diseño para realizar el tuneo de los hiperparámetros…</p>
</div>
</div>
</div>
<div id="entrenando-modelos-train" class="section level2">
<h2>Entrenando modelos (<code>train()</code>)</h2>
<p>Tenemos listo nuestro esquema de remuestreo. Podemos pasar a entrenar nuestro primer modelo. Para ello haremos uso extensivo de la función <code>train()</code>. La misma puede usarse para</p>
<ul>
<li>evaluar mediante remuestreo el efecto de cada hiperparámetro en la performance</li>
<li>elegir el modelo “óptimo” (la mejor combinación de parámetros)</li>
<li>estimar la performance del modelo</li>
</ul>
<p>Primero, debemos elegir el modelo para entrenar. Actualmente, <code>caret</code> dispone de 238 modelos disponibles. Puede consultarse <a href="http://topepo.github.io/caret/available-models.html">la seccion correspondiente</a> del sitio para mayores detalles. También, llegado el caso, podrían usarse modelos ad-hoc definidos por el usuario.</p>
<p>Comencemos con un modelo simple, pero efectivo: una regresión lineal. Como podrán ver en el sitio, cada modelo puede ser estimado por diferentes implementaciones en diferentes paquetes. Nosotros usaremos la implementación de r-base <code>lm()</code> por simplicidad.</p>
<p>Entrenemos una regresión lineal con caret: comencemos con un modelo simple, sexo y edad.</p>
<pre class="r"><code>lm_p21 &lt;- train(p21 ~ ch04 + ch06, data = df_train, 
                 method = &quot;lm&quot;, 
                 trControl = fitControl)

lm_p21</code></pre>
<pre><code>## Linear Regression 
## 
## 13587 samples
##     2 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 10869, 10870, 10869, 10870, 10870 
## Resampling results:
## 
##   RMSE      Rsquared    MAE     
##   5467.938  0.05437068  3812.111
## 
## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE</code></pre>
<p>Veamos los coeficientes…</p>
<pre class="r"><code>lm_p21$finalModel</code></pre>
<pre><code>## 
## Call:
## lm(formula = .outcome ~ ., data = dat)
## 
## Coefficients:
## (Intercept)    ch04Varón         ch06  
##     3088.65      2032.37        67.86</code></pre>
<p>Veamos, ahora, un modelo más complejo:</p>
<pre class="r"><code>lm_p21_b &lt;- train(p21 ~ ., data = df_train, 
                 method = &quot;lm&quot;, 
                 trControl = fitControl)</code></pre>
<pre class="r"><code>lm_p21_b</code></pre>
<pre><code>## Linear Regression 
## 
## 13587 samples
##    25 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 10869, 10870, 10869, 10870, 10870 
## Resampling results:
## 
##   RMSE      Rsquared   MAE     
##   3899.234  0.5200449  2467.764
## 
## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE</code></pre>
<p>Los modelos de machine learning tienen ciertos parámetros que deben ser seleccionados antes de estimar el modelo, propiamente dicho: se llaman <a href="https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)"><strong>hiperparámetros</strong></a>. Si bien la regresión lineal no es estrictamente hablando un modelo de machine learning (aunque muches lo consideran como tal) sí tiene algo que se le parece bastante a un hiperparámetro… la existencia de un intercepto. En efecto, nosotros estimamos un modelo de la siguiente forma:</p>
<p><span class="math inline">\(y_{i} = \beta_{0} + \sum_{p=1}^P \beta_{p} X_{i}\)</span></p>
<p>Pero podríamos haber estimado</p>
<p><span class="math inline">\(y_{i} = \sum_{p=1}^P \beta_{p} X_{i}\)</span></p>
<p>Más allá de la discusión sobre si la regresión es ML o no, lo interesante es ver que la decisión sobre el entrenamiento de un modelo lineal con intercepto o no, es una decisión que se toma antes de entrenar el modelo propiamente dicho.</p>
<p>Ahora bien, vamos a buscar otro modelo con mejores hiperparámetros para tunear: un árbol de decisión. Si bien, no vamos a profundizar en sus detalles técnicos, podemos revisar su implementación en caret.</p>
<div id="tuneando-hiperparámetros" class="section level3">
<h3>3. Tuneando hiperparámetros…</h3>
<p>Vamos a entrenar un <a href="https://en.wikipedia.org/wiki/Decision_tree_learning">árbol de decisión</a>. Podemos entonces, comparar la performance de diferentes combinaciones de hiperparámetros. Para ello, primero tenemos que construir la grilla de hiperparámetros.</p>
<pre class="r"><code>grid &lt;- expand.grid(maxdepth=c(1, 2, 4, 8, 16))</code></pre>
<p>El parámatro <code>maxdepth</code> permite definir la “profundidad” del árbol, es decir, cuántos niveles tiene. A mayor profundidad, mayor complejidad del modelo. Queda claro que antes de construir el árbol, tendría que definir qué tan profundo debería ser el mismo, por ello se trata de un <em>hiperparámetro</em>.</p>
<p>Y volvemos a entrenar el modelo:</p>
<pre class="r"><code>cart_p21 &lt;- train(p21 ~ . , 
                 data = df_train, 
                 method = &quot;rpart2&quot;, 
                 trControl = fitControl,
                 tuneGrid =grid)

cart_p21</code></pre>
<pre><code>## CART 
## 
## 13587 samples
##    25 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 10869, 10870, 10869, 10870, 10870 
## Resampling results across tuning parameters:
## 
##   maxdepth  RMSE      Rsquared   MAE     
##    1        5087.452  0.1815060  3341.331
##    2        4934.340  0.2300096  3238.701
##    4        4676.840  0.3085795  3081.847
##    8        4434.114  0.3788028  2837.224
##   16        4414.748  0.3842324  2818.607
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was maxdepth = 16.</code></pre>
<p>En este caso, hemos realizado una búsqueda exhaustiva, es decir, hemos recorrido la totalidad de la grilla de hiperparámetros y hemos seleccionado el mejor modelo. Como puede verse, esto ha llevado un tiempo de cómputo nada despreciable.</p>
<p>Es por ello que existe una segunda opción…</p>
</div>
<div id="random-search" class="section level3">
<h3>Random search</h3>
<p>En este caso, en lugar de realizar una búsqueda exhaustiva, podemos reducir notablemente el tiempo de cómputo buscando en una muestra aleatoria de la grilla de hiperparámetros. Para esto, solamente debemos agregar el parámetro <code>search</code> y setearlo en <code>'random'</code> en el objeto <code>fitControl</code>:</p>
<pre class="r"><code>fitControl_rand &lt;- trainControl(
        index=cv_index, 
        method=&quot;cv&quot;,
        number=5,
        search = &#39;random&#39;)</code></pre>
<p>Y volvemos a entrenar el modelo:</p>
<pre class="r"><code>cart_p21_rand &lt;- train(p21 ~ ., data = df_train, 
                 method = &quot;rpart2&quot;, 
                 trControl = fitControl_rand,
                 tuneLength = 2)

cart_p21_rand</code></pre>
<pre><code>## CART 
## 
## 13587 samples
##    25 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 10869, 10870, 10869, 10870, 10870 
## Resampling results across tuning parameters:
## 
##   maxdepth  RMSE      Rsquared   MAE     
##   1         5087.452  0.1815060  3341.331
##   4         4430.676  0.3798149  2830.611
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was maxdepth = 4.</code></pre>
</div>
</div>
<div id="seleccionando-el-mejor-modelo" class="section level2">
<h2>Seleccionando el mejor modelo</h2>
<p>Una vez finalizado el proceso de tunning de los hiperparámetros, podemos proceder a elegir cuál es el mejor modelo.</p>
<pre class="r"><code>cart_p21</code></pre>
<pre><code>## CART 
## 
## 13587 samples
##    25 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 10869, 10870, 10869, 10870, 10870 
## Resampling results across tuning parameters:
## 
##   maxdepth  RMSE      Rsquared   MAE     
##    1        5087.452  0.1815060  3341.331
##    2        4934.340  0.2300096  3238.701
##    4        4676.840  0.3085795  3081.847
##    8        4434.114  0.3788028  2837.224
##   16        4414.748  0.3842324  2818.607
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was maxdepth = 16.</code></pre>
<p>Podemos persistir el modelo en disco (si quisiéramos):</p>
<pre class="r"><code>saveRDS(cart_p21, &#39;p21_cart.rds&#39;)</code></pre>
<p>Podemos realizar un plot del efecto de los hiperparámetros:</p>
<pre class="r"><code>ggplot(cart_p21)</code></pre>
<p><img src="/post/2020-02-02-introducci%C3%B3n-simple-a-caret_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>Existen diferentes métricas de selección, las cuales deben ser definidas en la función <code>train</code>, usando el argumento <code>selectionFunction</code> que puede tomar tres valores:</p>
<ul>
<li><code>&quot;best&quot;</code>: se selecciona el mejor modelo con la menor métrica de error (la que usaremos aquí)</li>
<li><code>&quot;oneSE&quot;</code>: utiliza la regla de “un desvío estándar” de <a href="https://books.google.com.ar/books/about/Classification_and_Regression_Trees.html?id=JwQx-WOmSyQC&amp;redir_esc=y&amp;hl=es">Breiman et al (1986)</a></li>
<li><code>&quot;tolerance</code>; que busca seleccionar el modelo menos complejo dentro de un margen de tolerancia respecto al mejor modelo</li>
</ul>
<p>También podrían definirse métodos ad-hoc para esta selección.</p>
<pre class="r"><code>cart_p21$bestTune</code></pre>
<pre><code>##   maxdepth
## 5       16</code></pre>
<p>¿Cuál es el mejor modelo (en términos absolutos)?</p>
</div>
<div id="realizando-la-evaluación-final" class="section level2">
<h2>Realizando la evaluación final</h2>
<p>Una vez que hemos seleccionado el mejor modelo, podemos pasar a la evaluación final y persistimos el modelo para reutilizarlo en otras aplicaciones. Vemos entonces que el modelo seleccionado performa con un <span class="math inline">\(R^2=0.34\)</span> y un <span class="math inline">\(RMSE=4770\)</span>. Solamente nos quedaría re-entrenar el modelo final (el mejor) sobre la totalidad del dataset de entrenamiento:</p>
<pre class="r"><code>cart_p21</code></pre>
<pre><code>## CART 
## 
## 13587 samples
##    25 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 10869, 10870, 10869, 10870, 10870 
## Resampling results across tuning parameters:
## 
##   maxdepth  RMSE      Rsquared   MAE     
##    1        5087.452  0.1815060  3341.331
##    2        4934.340  0.2300096  3238.701
##    4        4676.840  0.3085795  3081.847
##    8        4434.114  0.3788028  2837.224
##   16        4414.748  0.3842324  2818.607
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was maxdepth = 16.</code></pre>
<p>Lo interesante es que de forma automática Í<code>caret</code> selecciona el emjor modelo y lo entrena sobre la totalidad del dataset.</p>
<div id="obteniendo-las-predicciones-finales" class="section level3">
<h3>4. Obteniendo las predicciones finales</h3>
<p>El último paso es obtener las predicciones finales (es decir, nuestras imputaciones). De forma interesante, podemos utilizar lso datos perdidos como datos “nuevos” y desconocidos.</p>
<p>Es decir que, finalmente, habremos realizado una imputación de datos perdidos. Para ello, llamamos a la función <code>predict()</code> que toma como primer argumento al objeto que contiene al modelo final y como segundo argumento el data.frame con los datos a imputar:</p>
<pre class="r"><code>y_preds_cart &lt;- predict(cart_p21, df_test)</code></pre>
<p>Testeemos, entonces, el modelo final, calculemos el error final:</p>
<pre class="r"><code>sqrt(mean((y_preds_cart - df_test$p21)**2))</code></pre>
<pre><code>## [1] 4925.883</code></pre>
</div>
<div id="pasando-en-limpio" class="section level3">
<h3>5. Pasando en limpio</h3>
<p><code>caret</code> es un paquete que trata de “unificar” las múltiples librerías en R para modelado predictivo. Permite estandarizar bastante el flujo de trabajo en sus diferentes etapas. De hecho, podemos diseñar un flujo de trabajo simple en unas pocas líneas de código:</p>
<pre class="r"><code>## Spliting
train_index &lt;- createDataPartition(y = df$p21,
                                   p=0.7,
                                   list=FALSE)

## Estrategia de tuneo
fitControl &lt;- trainControl(
        index=cv_index,
        method=&quot;cv&quot;,
        number=5)

## Grilla de hiperparámetros
grid &lt;- expand.grid(maxdepth=c(1, 2, 4, 8, 16))


## Training
cart_p21 &lt;- train(p21 ~ . , 
                 data = df_train, 
                 method = &quot;rpart2&quot;, 
                 trControl = fitControl,
                 tuneGrid =grid)

## Validación final
y_preds_cart &lt;- predict(cart_p21, df_test)
sqrt(mean((y_preds_cart - df_test$p21)**2))</code></pre>
</div>
</div>

                    </div>
                    
                    
                    <div class="after-post-tags">
                        <ul class="tags">
                        
                        <li>
                        <a href="/tags/caret">caret</a>
                        </li>
                        
                        </ul>
                    </div>
                    
                    
                    
                    <div class="row PageNavigation d-flex justify-content-between font-weight-bold">
                    
                    
                        <a class="d-block col-md-6 text-lg-right" href="https://elradar.github.io/2019/11/16/stringr/">Introducción al análisis de texto &raquo;</a>
                    
                    <div class="clearfix"></div>
                    </div>
                    
                </div>
                
            </div>
        </div>
        
        
<div class="container">
    <div id="comments" class="row justify-content-center mb-5">
        <div class="col-md-8">              
                           
        </div>
    </div>
</div>

    </div>


            </div>
<div class="jumbotron fortags">
	<div class="d-md-flex h-100">
		<div class="col-md-4 transpdark align-self-center text-center h-100">
			<div class="d-md-flex align-items-center justify-content-center h-100">
				<h2 class="d-md-block d-none align-self-center py-1 font-weight-light"> Ver también <span class="d-none d-md-inline">→</span></h2>
			</div>
		</div>
		<div class="col-md-8 p-5 align-self-center text-center">
			
			<a class="mt-1 mb-1" href="/tags/caret">caret</a>
			
			<a class="mt-1 mb-1" href="/tags/data-wrangling">data-wrangling</a>
			
			<a class="mt-1 mb-1" href="/tags/educaci%C3%B3n">educación</a>
			
			<a class="mt-1 mb-1" href="/tags/eph">eph</a>
			
			<a class="mt-1 mb-1" href="/tags/etl">etl</a>
			
			<a class="mt-1 mb-1" href="/tags/genero">genero</a>
			
			<a class="mt-1 mb-1" href="/tags/inequidad">inequidad</a>
			
			<a class="mt-1 mb-1" href="/tags/janitor">janitor</a>
			
			<a class="mt-1 mb-1" href="/tags/limpieza">limpieza</a>
			
			<a class="mt-1 mb-1" href="/tags/osrm">osrm</a>
			
			<a class="mt-1 mb-1" href="/tags/ruteo">ruteo</a>
			
			<a class="mt-1 mb-1" href="/tags/stringr">stringr</a>
			
			<a class="mt-1 mb-1" href="/tags/transformacion">transformacion</a>
			
			<a class="mt-1 mb-1" href="/tags/wordclouds">wordclouds</a>
			
		</div>
	</div>
</div>

<footer class="footer">
    <div class="container">
        <div class="row">
            <div class="col-md-6 col-sm-6 text-center text-lg-left">
                &copy; Copyright equipo el radaR
            </div>
            <div class="col-md-6 col-sm-6 text-center text-lg-right">    
                Mediumish Theme por WowThemes.net
            </div>
        </div>
    </div>
</footer>


        </div>


<script src="https://code.jquery.com/jquery-3.3.1.min.js"></script>
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script>

<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js" integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k" crossorigin="anonymous"></script>

<script src="/js/mediumish.js"></script>

    </body>
</html>
